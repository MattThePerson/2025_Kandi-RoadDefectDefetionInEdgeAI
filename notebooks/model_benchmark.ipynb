{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n"
   ],
   "id": "ff6a3b1593e1cc7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "This benchmarking script will run the chosen models on test data and save the results.\n",
    "\n",
    "You can run this script with the following arguments:\n",
    "    -mf models/ -s RDD2022_PP.yaml -n benchmarking_test --imgsz 640\n",
    "this should be equivalent with the following CLI command:\n",
    "    yolo detect val model=\"models/model_name.pt\" data=\"RDD2022_PP.yaml\" split=\"test\" project=\"benchmarks\" imgsz=640 name=\"benchmarking_test\"\n",
    "\n",
    "\"\"\"\n",
    "# os.chdir('2025_Kandi-RoadDefectDefetionInEdgeAI')\n",
    "print(os.getcwd())\n",
    "models = os.listdir(\"models/\")  # directory of models to be tested\n",
    "print(models)\n",
    "source = \"YAML/RDD2022_kaikki.yaml\"\n",
    "name = \"benchmarking_test\"\n",
    "imgsz = 640\n",
    "split = \"test\"\n",
    "project = \"benchmarks\"\n",
    "name=\"benchmarking_test\"\n",
    "save_video=False"
   ],
   "id": "b5f06aea68df8c04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "18802ad9500915ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"Run the benchmarks on the data, this may take a while.\"\n",
    "results = dict()\n",
    "\n",
    "for model in models:\n",
    "    model = YOLO(model)  # load model\n",
    "    result = model.val(\n",
    "                        data=source,\n",
    "                        #stream=True,\n",
    "                        imgsz=imgsz,\n",
    "                        project=project,\n",
    "                        save=save_video,  # saves a video with the bounding boxes\n",
    "                        task='detect',\n",
    "                        name=name,\n",
    "                        split=split)\n",
    "\n",
    "    results[model] = result\n",
    "   \n",
    "   "
   ],
   "id": "3e06e65ad7837e19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"print results to console\"\n",
    "for result in results:\n",
    "    # print(result)  # prints the YOLO architecture\n",
    "    # print(vars(result))\n",
    "    # print(result.metrics)  # print all metrics\n",
    "    print(\"keys\", result.metrics.keys)\n",
    "    # pprint(result.metrics.mean_results)\n",
    "    print(\"Class Box(P   R      mAP50  mAP50-95)\")\n",
    "    print(\"All  \",\n",
    "          [round(result.metrics.results_dict[\"metrics/precision(B)\"], 3),\n",
    "          round(result.metrics.results_dict[\"metrics/recall(B)\"], 3),\n",
    "          round(result.metrics.results_dict[\"metrics/mAP50(B)\"], 3),\n",
    "          round(result.metrics.results_dict[\"metrics/mAP50-95(B)\"], 3)]\n",
    "          )\n",
    "    print(\"D00  \", [round(r, 3) for r in result.metrics.class_result(0)])\n",
    "    print(\"D10  \", [round(r, 3) for r in result.metrics.class_result(1)])\n",
    "    print(\"D20  \", [round(r, 3) for r in result.metrics.class_result(2)])\n",
    "    print(\"D40  \", [round(r, 3) for r in result.metrics.class_result(3)])\n",
    "    # print(\"mAP50-95\", result.metrics.maps)  # print all mAP50-95 results\n",
    "    print(\"fitness\", round(result.metrics.fitness, 4))\n",
    "    print(\"results_dict\", result.metrics.results_dict)"
   ],
   "id": "a80512864344f86b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"put results to a pandas array\"\n",
    "\n",
    "pd_results = dict()\n",
    "\n",
    "for result in results:\n",
    "    # print(result)  # prints the YOLO architecture\n",
    "    # print(vars(result))\n",
    "    # print(result.metrics)  # print all metrics\n",
    "    keys = pd.array(result.metrics.keys).insert(0, \"Class\")\n",
    "    print(\"keys\", keys)\n",
    "    \n",
    "    pd_results = pd.array()\n",
    "    \n",
    "    # pprint(result.metrics.mean_results)\n",
    "    print(\"Class Box(P   R      mAP50  mAP50-95)\")\n",
    "    print(\"All  \",\n",
    "          [round(result.metrics.results_dict[\"metrics/precision(B)\"], 3),\n",
    "          round(result.metrics.results_dict[\"metrics/recall(B)\"], 3),\n",
    "          round(result.metrics.results_dict[\"metrics/mAP50(B)\"], 3),\n",
    "          round(result.metrics.results_dict[\"metrics/mAP50-95(B)\"], 3)]\n",
    "          )\n",
    "    print(\"D00  \", [round(r, 3) for r in result.metrics.class_result(0)])\n",
    "    print(\"D10  \", [round(r, 3) for r in result.metrics.class_result(1)])\n",
    "    print(\"D20  \", [round(r, 3) for r in result.metrics.class_result(2)])\n",
    "    print(\"D40  \", [round(r, 3) for r in result.metrics.class_result(3)])\n",
    "    # print(\"mAP50-95\", result.metrics.maps)  # print all mAP50-95 results\n",
    "    print(\"fitness\", round(result.metrics.fitness, 4))\n",
    "    print(\"results_dict\", result.metrics.results_dict)"
   ],
   "id": "32cf63fb2aa4bd74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "938eef0c75ae8a16",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
